# ðŸ”´ Why compare different ML Models?

## Problem
There are a bunch of good Machine-Learning models out there that you can use for you specific task or use-case. The problem is, most of the time you have to **pay** to use them, they are pre-trained for a **general usage** not for your specfifc problem and you are totally **dependant** from the company that is running the model. Depending on your use-case and in which country you operate, there are also **privacy issues** as you have to send you potentially sensible data to their API to their servers, where ever these are located.

## Solution
First of all, you can compare different models so that you find the one, that provides the **best results** for your specific use-case. That way you are also **mitigating your risks** because you are not dependant from one model or company. But you can also then try to run this model locally and therefor have **no more privacy issues** and also only have to pay the **costs** for your infrastructure but don't have to pay for the usage of an API any more.

## How To
We will compare 3 different models. The classic **GPT-4-Turbo** using the OpenAI API, we will download the **small Llama3** model (8 billion parameters) to run it locally and we will use Groq API to run the **big Llama3** model (70 billion parameters):

![CompareModels](https://github.com/Tobander/MLProject-CompareModels/assets/45336196/6d31b842-30d1-4236-91e1-aff023067a1e)
